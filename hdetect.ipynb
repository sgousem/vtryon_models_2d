{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(309, 685), (241, 625), (174, 524), (134, 484), (80, 423), (282, 464), (268, 363), (282, 302), (282, 242), (335, 464), (335, 342), (349, 282), (362, 221), (362, 484), (403, 383), (416, 322), (429, 262), (403, 504), (456, 464), (483, 403), (510, 383)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "BODY_PARTS = { \"Wrist\": 0,\n",
    "                   \"ThumbMetacarpal\": 1, \"ThumbProximal\": 2, \"ThumbMiddle\": 3, \"ThumbDistal\": 4,\n",
    "                   \"IndexFingerMetacarpal\": 5, \"IndexFingerProximal\": 6, \"IndexFingerMiddle\": 7, \"IndexFingerDistal\": 8,\n",
    "                   \"MiddleFingerMetacarpal\": 9, \"MiddleFingerProximal\": 10, \"MiddleFingerMiddle\": 11, \"MiddleFingerDistal\": 12,\n",
    "                   \"RingFingerMetacarpal\": 13, \"RingFingerProximal\": 14, \"RingFingerMiddle\": 15, \"RingFingerDistal\": 16,\n",
    "                   \"LittleFingerMetacarpal\": 17, \"LittleFingerProximal\": 18, \"LittleFingerMiddle\": 19, \"LittleFingerDistal\": 20,\n",
    "                 }\n",
    "\n",
    "POSE_PAIRS = [ [\"Wrist\", \"ThumbMetacarpal\"], [\"ThumbMetacarpal\", \"ThumbProximal\"],\n",
    "               [\"ThumbProximal\", \"ThumbMiddle\"], [\"ThumbMiddle\", \"ThumbDistal\"],\n",
    "               [\"Wrist\", \"IndexFingerMetacarpal\"], [\"IndexFingerMetacarpal\", \"IndexFingerProximal\"],\n",
    "               [\"IndexFingerProximal\", \"IndexFingerMiddle\"], [\"IndexFingerMiddle\", \"IndexFingerDistal\"],\n",
    "               [\"Wrist\", \"MiddleFingerMetacarpal\"], [\"MiddleFingerMetacarpal\", \"MiddleFingerProximal\"],\n",
    "               [\"MiddleFingerProximal\", \"MiddleFingerMiddle\"], [\"MiddleFingerMiddle\", \"MiddleFingerDistal\"],\n",
    "               [\"Wrist\", \"RingFingerMetacarpal\"], [\"RingFingerMetacarpal\", \"RingFingerProximal\"],\n",
    "               [\"RingFingerProximal\", \"RingFingerMiddle\"], [\"RingFingerMiddle\", \"RingFingerDistal\"],\n",
    "               [\"Wrist\", \"LittleFingerMetacarpal\"], [\"LittleFingerMetacarpal\", \"LittleFingerProximal\"],\n",
    "               [\"LittleFingerProximal\", \"LittleFingerMiddle\"], [\"LittleFingerMiddle\", \"LittleFingerDistal\"] ]\n",
    "protoFile = \"pose_deploy.prototxt\"\n",
    "weightsFile = \"pose_iter_102000.caffemodel\"\n",
    "nPoints = 22\n",
    "inWidth = 368\n",
    "inHeight = 368\n",
    "frame = cv2.imread(\"hand1.jpg\")\n",
    "frameCopy = frame.copy()\n",
    "frameWidth = frame.shape[1]\n",
    "frameHeight = frame.shape[0]\n",
    "threshold = 0.1\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "#Get predictions\n",
    "inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),(0, 0, 0), swapRB=False, crop=False)\n",
    "net.setInput(inpBlob)\n",
    "out = net.forward()\n",
    "#Shoe detections\n",
    "points = []\n",
    "'''\n",
    "for i in range(nPoints):\n",
    "    # confidence map of corresponding body's part.\n",
    "    probMap = output[0, i, :, :]\n",
    "    probMap = cv2.resize(probMap, (frameWidth, frameHeight))\n",
    "\n",
    "    # Find global maxima of the probMap.\n",
    "    minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "    if prob > threshold :\n",
    "        cv2.circle(frameCopy, (int(point[0]), int(point[1])), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "        cv2.putText(frameCopy, \"{}\".format(i), (int(point[0]), int(point[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "        # Add the point to the list if the probability is greater than the threshold\n",
    "        points.append((int(point[0]), int(point[1])))\n",
    "    else :\n",
    "        points.append(None)\n",
    "        #cv2.imshow('Output-Keypoints', frameCopy)\n",
    "# Draw Skeleton\n",
    "for pair in POSE_PAIRS:\n",
    "    partA = pair[0]\n",
    "    partB = pair[1]\n",
    "\n",
    "    if points[partA] and points[partB]:\n",
    "        cv2.line(frame, points[partA], points[partB], (0, 255, 255), 2)\n",
    "        cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "cv2.imshow('Output-Skeleton', frame)\n",
    "    #if cv2.waitKey(3000) & 0xFF == ord('q'):\n",
    "        #break\n",
    "\n",
    "#cap.release() \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "for i in range(len(BODY_PARTS)):\n",
    "    # Slice heatmap of corresponging body's part.\n",
    "    heatMap = out[0, i, :, :]\n",
    "\n",
    "    # Originally, we try to find all the local maximums. To simplify a sample\n",
    "    # we just find a global one. However only a single pose at the same time\n",
    "    # could be detected this way.\n",
    "    _, conf, _, point = cv2.minMaxLoc(heatMap)\n",
    "    x = (frameWidth * point[0]) / out.shape[3]\n",
    "    y = (frameHeight * point[1]) / out.shape[2]\n",
    "    # Add a point if it's confidence is higher than threshold.\n",
    "    points.append((int(x), int(y)) if conf > 0.1 else None)\n",
    "    #print(point[0],point[1])\n",
    "print(points)\n",
    "for pair in POSE_PAIRS:\n",
    "    partFrom = pair[0]\n",
    "    partTo = pair[1]\n",
    "    assert(partFrom in BODY_PARTS)\n",
    "    assert(partTo in BODY_PARTS)\n",
    "\n",
    "    idFrom = BODY_PARTS[partFrom]\n",
    "    idTo = BODY_PARTS[partTo]\n",
    "    #print(idFrom,idTo)\n",
    "    if points[idFrom] and points[idTo]:\n",
    "        cv2.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)\n",
    "        cv2.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv2.FILLED)\n",
    "        cv2.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv2.FILLED)\n",
    "        #D = dist.euclidean((points[idFrom][0],points[idTo][0]), (points[idFrom][1],points[idTo][1]))\n",
    "        distance = math.sqrt( ((points[idFrom][0]-points[idTo][0])**2)+((points[idFrom][1]-points[idTo][1])**2) )\n",
    "\n",
    "        #print(distance)\n",
    "distance1 = math.sqrt( ((points[2][0]-points[5][0])**2)+((points[2][1]-points[5][1])**2) )\n",
    "#print(distance1)\n",
    "t, _ = net.getPerfProfile()\n",
    "freq = cv2.getTickFrequency() / 1000\n",
    "cv2.putText(frame, '%.2fms' % (t / freq), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "cv2.imshow('OpenPose using OpenCV', frame)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(282, 464), (268, 363), (282, 302), (282, 242)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[5:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(335, 464), (335, 342), (349, 282), (362, 221)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[9:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 103, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hring = cv2.imread('hring1.jpg')\n",
    "hring.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "#rotation angle in degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "(76, 56)\n",
      "(56, 76, 3)\n",
      "(56, 76)\n",
      "(56, 76)\n",
      "(56, 76, 3)\n",
      "(56, 76, 3)\n",
      "(56, 76, 3)\n",
      "(56, 76, 3)\n",
      "56\n",
      "(76, 56)\n",
      "(56, 76, 3)\n",
      "(56, 76)\n",
      "(56, 76)\n",
      "(56, 76, 3)\n",
      "(56, 76, 3)\n",
      "(56, 76, 3)\n",
      "(56, 76, 3)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    image1 = cv2.imread('hring.jpg')\n",
    "    #image1 = ndimage.rotate(image1, -30)\n",
    "    rows = image1.shape[0]\n",
    "    cols = image1.shape[1]\n",
    "    img_center = (cols / 2, rows / 2)\n",
    "    M = cv2.getRotationMatrix2D(img_center, -40, 1)\n",
    "    image1 = cv2.warpAffine(image1, M, (cols, rows),borderMode=cv2.BORDER_CONSTANT,borderValue=(255,255,255))\n",
    "    print(image1.shape[0])\n",
    "    dim = (int(image1.shape[1]),int(image1.shape[0]))\n",
    "    print(dim)\n",
    "    img2gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # add a threshold\n",
    "    ret, mask = cv2.threshold(img2gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "    #cv2.imshow('Ear Detector', ear_img) \n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    resized = cv2.resize(image1,dim, interpolation = cv2.INTER_AREA)\n",
    "    print(resized.shape)\n",
    "    mask = cv2.resize(mask, (resized.shape[1],resized.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "    print(mask.shape)\n",
    "    mask_inv = cv2.resize(mask_inv, (resized.shape[1],resized.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "    print(mask_inv.shape)\n",
    "\n",
    "    roi = frame[350:350+dim[1],300:300+dim[0]]\n",
    "    #print(s1,point,point1,point1+dim[0])\n",
    "    print(roi.shape)\n",
    "\n",
    "    #print(point,point1)\n",
    "    roi_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "    print(roi_bg.shape)\n",
    "    # roi_fg contains the orignal location of earring\n",
    "    roi_fg = cv2.bitwise_and(resized,resized,mask = mask)\n",
    "    print(roi_bg.shape)\n",
    "    # joining the roi_bg and roi_fg\n",
    "    dst = cv2.add(roi_bg,roi_fg)\n",
    "    print(dst.shape)\n",
    "    #cv2.imshow('Ear Detector', dst) \n",
    "    #cv2.waitKey(10)\n",
    "    #point = int(s1+dim[0])\n",
    "    #print(point,point+dim[0])\n",
    "    #cv2.circle(image, (s1,s2+80), 3, (0, 255, 0), -1)\n",
    "\n",
    "    #cv2.rectangle(image, (s1,s2+80), (s1+dim[0],s2+80+dim[1]), (0,255,0), 3)\n",
    "    frame[350:350+dim[1],300:300+dim[0]]=dst\n",
    "    #cv2.imshow('resize traget',roi )\n",
    "    #cv2.imshow('resize traget',resized )\n",
    "    cv2.imshow('Ear Detector', frame)\n",
    "    #cv2.imshow('Ear Detector', dst)\n",
    "\n",
    "    #c = cv2.waitKey(1) \n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "#cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad transparency mask",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-8421a540f819>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mnew_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGBA'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'white'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mAlpha_Image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomposite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mAlpha_Image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAlpha_Image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mcomposite\u001b[1;34m(image1, image2, mask)\u001b[0m\n\u001b[0;32m   2874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2875\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2876\u001b[1;33m     \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2877\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mpaste\u001b[1;34m(self, im, box, mask)\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m             \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1524\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1525\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad transparency mask"
     ]
    }
   ],
   "source": [
    "rotated_image = cv2.warpAffine(image1, M, (cols, rows),\n",
    "                           borderMode=cv2.BORDER_CONSTANT,\n",
    "                           borderValue=(0,255,0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
