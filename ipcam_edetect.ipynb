{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(657, 311, 3)\n",
      "[[170 176  69 115]]\n",
      "(720, 480, 3)\n",
      "[[147 169  58  97]\n",
      " [133 150  75 125]]\n",
      "(720, 480, 3)\n",
      "[[195 174  69 116]]\n",
      "(720, 480, 3)\n",
      "()\n",
      "(720, 480, 3)\n",
      "()\n",
      "(720, 480, 3)\n",
      "()\n",
      "(720, 480, 3)\n",
      "[[ 31 180  64 107]]\n",
      "(720, 480, 3)\n",
      "[[118 192  68 114]]\n",
      "(720, 480, 3)\n",
      "[[143 196  75 125]]\n",
      "(720, 480, 3)\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from cv2 import cv2 \n",
    "import numpy as np \n",
    " \n",
    "left_ear_cascade = cv2.CascadeClassifier('haarcascade_mcs_leftear.xml') \n",
    "right_ear_cascade = cv2.CascadeClassifier('haarcascade_mcs_rightear.xml') \n",
    " \n",
    "if left_ear_cascade.empty(): \n",
    "  raise IOError('Unable to load the left ear cascade classifier xml file') \n",
    " \n",
    "if right_ear_cascade.empty(): \n",
    "  raise IOError('Unable to load the right ear cascade classifier xml file') \n",
    " \n",
    "#cap = cv2.VideoCapture(0)\n",
    "#scaling_factor = 0.5\n",
    "image = cv2.imread('er2.jpg') \n",
    "print(image.shape)\n",
    "URL = \"http://192.168.43.1:8080/shot.jpg\"\n",
    "#img_arr = np.array(bytearray(urllib.request.urlopen(URL).read()),dtype=np.uint8)\n",
    "while True:    \n",
    "    img_arr = np.array(bytearray(urllib.request.urlopen(URL).read()),dtype=np.uint8)\n",
    "    #print(img_arr)\n",
    "    frame = cv2.imdecode(img_arr,-1)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  \n",
    "    cv2.imshow('Ear Detector', gray)\n",
    "    left_ear = left_ear_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=3) \n",
    "    right_ear = right_ear_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=3) \n",
    "    print(left_ear)\n",
    "    print(frame.shape)\n",
    "    for (x,y,w,h) in right_ear: \n",
    "        \n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)\n",
    "        cv2.circle(frame,(int(x+w*0.7),int(y+h*0.8)),5,(255,255,255),-1,8,0)\n",
    "        factor = auto_map_images(frame.shape[:-1],image.shape[:-1],(x,y,x+w,y+h))\n",
    "        dim = (int(image.shape[1]*factor),int(image.shape[0]*factor))\n",
    "        img2gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # add a threshold\n",
    "        ret, mask = cv2.threshold(img2gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "        #cv2.imshow('Ear Detector', ear_img) \n",
    "        mask_inv = cv2.bitwise_not(mask)\n",
    "        resized = cv2.resize(image,dim, interpolation = cv2.INTER_AREA)\n",
    "        mask = cv2.resize(mask, (resized.shape[1],resized.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "        mask_inv = cv2.resize(mask_inv, (resized.shape[1],resized.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "        print(resized.shape)\n",
    "        x1 = int(x+w*0.7)\n",
    "        x2 = x1 + dim[1]\n",
    "        y1 = int(y+h*0.8)\n",
    "        y2 = y1 + dim[0]\n",
    "        print(x2-x1,y2-y1)\n",
    "        print(x,y,x+w,y+h)\n",
    "        print(w,h)\n",
    "        if dim[0]%2==1:\n",
    "            roi = frame[int(y+h*0.8):int(y+h*0.8)+dim[1],int(x+w*0.7)-(int(dim[0]/2)):int(x+w*0.7)+(int(dim[0]/2)+1)]\n",
    "            print(roi.shape)\n",
    "            roi_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "            # roi_fg contains the orignal location of earring\n",
    "            roi_fg = cv2.bitwise_and(resized,resized,mask = mask)\n",
    "            # joining the roi_bg and roi_fg\n",
    "            dst = cv2.add(roi_bg,roi_fg)\n",
    "            cv2.imshow('Ear Detector', dst) \n",
    "            cv2.waitKey(10)\n",
    "            frame[int(y+h*0.8):int(y+h*0.8)+dim[1],int(x+w*0.7)-(int(dim[0]/2)):int(x+w*0.7)+(int(dim[0]/2)+1)]=dst\n",
    "        else:\n",
    "            roi = frame[int(y+h*0.8):int(y+h*0.8)+dim[1],int(x+w*0.7)-(int(dim[0]/2)):int(x+w*0.7)+(int(dim[0]/2))]\n",
    "            print(roi.shape)\n",
    "            roi_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "            # roi_fg contains the orignal location of earring\n",
    "            roi_fg = cv2.bitwise_and(resized,resized,mask = mask)\n",
    "            # joining the roi_bg and roi_fg\n",
    "            dst = cv2.add(roi_bg,roi_fg)\n",
    "            cv2.imshow('Ear Detector', dst) \n",
    "            cv2.waitKey(10)\n",
    "            frame[int(y+h*0.8):int(y+h*0.8)+dim[1],int(x+w*0.7)-(int(dim[0]/2)):int(x+w*0.7)+(int(dim[0]/2))]=dst\n",
    "\n",
    "    cv2.imshow('Ear Detector', frame)\n",
    "    #cv2.imshow('Ear Detector', dst)\n",
    "    \n",
    "    #c = cv2.waitKey(1) \n",
    "    if cv2.waitKey(3000) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_map_images(img_dim,tar_dim,det_dim):\n",
    "    mul_factor = (det_dim[2]-det_dim[0])/tar_dim[1]\n",
    "    #print(mul_factor)\n",
    "    new_tar_dim = tuple([int(mul_factor*x)for x in tar_dim])\n",
    "    #print(new_tar_dim)\n",
    "    left_space = img_dim[1]-det_dim[3]\n",
    "    #print(left_space)\n",
    "    if left_space>new_tar_dim[0]:\n",
    "        factor = mul_factor\n",
    "    else:\n",
    "        factor = left_space/tar_dim[0]\n",
    "    return factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 100, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n",
      "(720, 480, 3)\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from cv2 import cv2 \n",
    "import numpy as np \n",
    "def auto_map_images(img_dim,tar_dim,det_dim):\n",
    "    mul_factor = (det_dim[2]-det_dim[0])/tar_dim[1]\n",
    "    #print(mul_factor)\n",
    "    new_tar_dim = tuple([int(mul_factor*x)for x in tar_dim])\n",
    "    #print(new_tar_dim)\n",
    "    left_space = img_dim[1]-det_dim[3]\n",
    "    #print(left_space)\n",
    "    if left_space>new_tar_dim[0]:\n",
    "        factor = mul_factor\n",
    "    else:\n",
    "        factor = left_space/tar_dim[0]\n",
    "    return factor\n",
    "left_ear_cascade = cv2.CascadeClassifier('haarcascade_mcs_leftear.xml') \n",
    "right_ear_cascade = cv2.CascadeClassifier('haarcascade_mcs_rightear.xml') \n",
    " \n",
    "if left_ear_cascade.empty(): \n",
    "  raise IOError('Unable to load the left ear cascade classifier xml file') \n",
    " \n",
    "if right_ear_cascade.empty(): \n",
    "  raise IOError('Unable to load the right ear cascade classifier xml file') \n",
    " \n",
    "#cap = cv2.VideoCapture(0)\n",
    "#scaling_factor = 0.5\n",
    "image = cv2.imread('er.jpg') \n",
    "print(image.shape)\n",
    "URL = \"http://192.168.43.1:8080/shot.jpg\"\n",
    "#img_arr = np.array(bytearray(urllib.request.urlopen(URL).read()),dtype=np.uint8)\n",
    "while True:    \n",
    "    img_arr = np.array(bytearray(urllib.request.urlopen(URL).read()),dtype=np.uint8)\n",
    "    #print(img_arr)\n",
    "    frame = cv2.imdecode(img_arr,-1)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  \n",
    "    left_ear = left_ear_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=3) \n",
    "    right_ear = right_ear_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=3) \n",
    "    print(frame.shape)\n",
    "    for (x,y,w,h) in left_ear: \n",
    "        \n",
    "        #cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)\n",
    "        #cv2.circle(frame,(int(x+w*0.7),int(y+h*0.8)),5,(255,255,255),-1,8,0)\n",
    "        factor = auto_map_images(frame.shape[:-1],image.shape[:-1],(x,y,x+w,y+h))\n",
    "        dim = (int(image.shape[1]*factor),int(image.shape[0]*factor))\n",
    "        img2gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # add a threshold\n",
    "        ret, mask = cv2.threshold(img2gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "        #cv2.imshow('Ear Detector', ear_img) \n",
    "        mask_inv = cv2.bitwise_not(mask)\n",
    "        resized = cv2.resize(image,dim, interpolation = cv2.INTER_AREA)\n",
    "        resized1 = cv2.resize(resized, (resized.shape[1]*10,resized.shape[0]*10), interpolation = cv2.INTER_AREA)\n",
    "        #mask = cv2.resize(mask, (resized.shape[1],resized.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "        #mask_inv = cv2.resize(mask_inv, (resized.shape[1],resized.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "        mask = cv2.resize(mask, (resized.shape[1]*10,resized.shape[0]*10), interpolation = cv2.INTER_AREA)\n",
    "        mask_inv = cv2.resize(mask_inv, (resized.shape[1]*10,resized.shape[0]*10), interpolation = cv2.INTER_AREA)\n",
    "        print(resized.shape)\n",
    "        print(mask.shape)\n",
    "        print(mask_inv.shape)\n",
    "        x1 = int(x+w*0.7)\n",
    "        x2 = x1 + dim[1]\n",
    "        y1 = int(y+h*0.8)\n",
    "        y2 = y1 + dim[0]\n",
    "        print(x2-x1,y2-y1)\n",
    "        print(x,y,x+w,y+h)\n",
    "        print(w,h)\n",
    "        if dim[0]%2==1:\n",
    "            roi1 = frame[int(y+h*0.8):int(y+h*0.8)+dim[1],int(x+w*0.7)-(int(dim[0]/2)):int(x+w*0.7)+(int(dim[0]/2)+1)]\n",
    "            roi = cv2.resize(roi1, (roi1.shape[1]*10,roi1.shape[0]*10), interpolation = cv2.INTER_AREA)\n",
    "            print(roi.shape)\n",
    "            roi_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "            # roi_fg contains the orignal location of earring\n",
    "            roi_fg = cv2.bitwise_and(resized1,resized1,mask = mask)\n",
    "            # joining the roi_bg and roi_fg\n",
    "            dst1 = cv2.add(roi_bg,roi_fg)\n",
    "            dst = cv2.resize(dst1, (int(dst1.shape[1]/10),int(dst1.shape[0]/10)), interpolation = cv2.INTER_AREA)\n",
    "            cv2.imshow('Ear Detector', dst) \n",
    "            cv2.waitKey(10)\n",
    "            frame[int(y+h*0.8):int(y+h*0.8)+dim[1],int(x+w*0.7)-(int(dim[0]/2)):int(x+w*0.7)+(int(dim[0]/2)+1)]=dst\n",
    "        else:\n",
    "            roi1 = frame[int(y+h*0.8):int(y+h*0.8)+dim[1],int(x+w*0.7)-(int(dim[0]/2)):int(x+w*0.7)+(int(dim[0]/2))]\n",
    "            roi = cv2.resize(roi1, (roi1.shape[1]*10,roi1.shape[0]*10), interpolation = cv2.INTER_AREA)\n",
    "            print(roi.shape)\n",
    "            roi_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "            # roi_fg contains the orignal location of earring\n",
    "            roi_fg = cv2.bitwise_and(resized1,resized1,mask = mask)\n",
    "            # joining the roi_bg and roi_fg\n",
    "            dst1 = cv2.add(roi_bg,roi_fg)\n",
    "            dst = cv2.resize(dst1, (int(dst1.shape[1]/10),int(dst1.shape[0]/10)), interpolation = cv2.INTER_AREA)\n",
    "            cv2.imshow('Ear Detector', dst) \n",
    "            cv2.waitKey(10)\n",
    "            frame[int(y+h*0.8):int(y+h*0.8)+dim[1],int(x+w*0.7)-(int(dim[0]/2)):int(x+w*0.7)+(int(dim[0]/2))]=dst\n",
    "\n",
    "    cv2.imshow('Ear Detector', frame)\n",
    "    #cv2.imshow('Ear Detector', dst)\n",
    "    \n",
    "    #c = cv2.waitKey(1) \n",
    "    if cv2.waitKey(3000) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
