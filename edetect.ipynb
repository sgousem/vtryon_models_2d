{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 109, 3)\n",
      "(225, 225, 3)\n",
      "(60, 32, 3)\n",
      "60 32\n",
      "95 66 125 116\n",
      "30 50\n",
      "(60, 32, 3)\n",
      "(225, 225, 3)\n",
      "(60, 32, 3)\n",
      "60 32\n",
      "95 66 125 116\n",
      "30 50\n",
      "(60, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from cv2 import cv2 \n",
    "import numpy as np \n",
    " \n",
    "left_ear_cascade = cv2.CascadeClassifier('haarcascade_mcs_leftear.xml') \n",
    "right_ear_cascade = cv2.CascadeClassifier('haarcascade_mcs_rightear.xml') \n",
    " \n",
    "if left_ear_cascade.empty(): \n",
    "  raise IOError('Unable to load the left ear cascade classifier xml file') \n",
    " \n",
    "if right_ear_cascade.empty(): \n",
    "  raise IOError('Unable to load the right ear cascade classifier xml file') \n",
    " \n",
    "#cap = cv2.VideoCapture(0)\n",
    "#scaling_factor = 0.5\n",
    "image = cv2.imread('er1.jpg') \n",
    "print(image.shape)\n",
    "#factor = 0.1492\n",
    "dim = (int(image.shape[1]*0.3),int(image.shape[0]*0.3))\n",
    "img2gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# add a threshold\n",
    "ret, mask = cv2.threshold(img2gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "#cv2.imshow('Ear Detector', ear_img) \n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "resized = cv2.resize(image,dim, interpolation = cv2.INTER_AREA)\n",
    "mask = cv2.resize(mask, (resized.shape[1],resized.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "mask_inv = cv2.resize(mask_inv, (resized.shape[1],resized.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "#print(frame.shape)\n",
    "#dim = (int(image.shape[1]*0.20),int(image.shape[0]*0.20))\n",
    "while True:\n",
    "    #ret, frame = cap.read() \n",
    "    frame = cv2.imread('index4.jpg')\n",
    "    #frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  \n",
    "    left_ear = left_ear_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=3) \n",
    "    right_ear = right_ear_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=3) \n",
    "    print(frame.shape)\n",
    "    for (x,y,w,h) in left_ear: \n",
    "        \n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)\n",
    "        #cv2.circle(frame,(int(x+w*0.7),int(y+h*0.8)),5,(255,255,255),-1,8,0)\n",
    "        print(resized.shape)\n",
    "        x1 = int(x+w*0.7)\n",
    "        x2 = x1 + dim[1]\n",
    "        y1 = int(y+h*0.8)\n",
    "        y2 = y1 + dim[0]\n",
    "        print(x2-x1,y2-y1)\n",
    "        print(x,y,x+w,y+h)\n",
    "        print(w,h)\n",
    "        roi = frame[int(y+h*0.8):int(y+h*0.8)+dim[1],int(x+w*0.7)-(int(dim[0]/2)):int(x+w*0.7)+(int(dim[0]/2))]\n",
    "        print(roi.shape)\n",
    "        roi_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "        # roi_fg contains the orignal location of earring\n",
    "        roi_fg = cv2.bitwise_and(resized,resized,mask = mask)\n",
    "        # joining the roi_bg and roi_fg\n",
    "        dst = cv2.add(roi_bg,roi_fg)\n",
    "        cv2.imshow('Ear Detector', dst) \n",
    "        cv2.waitKey(10)\n",
    "        frame[int(y+h*0.8):int(y+h*0.8)+dim[1],int(x+w*0.7)-(int(dim[0]/2)):int(x+w*0.7)+(int(dim[0]/2))]=dst\n",
    "        \n",
    "    for (x,y,w,h) in right_ear: \n",
    "        cv2.rectangqle(frame, (x,y), (x+w,y+h), (255,0,0), 3) \n",
    "\n",
    "    cv2.imshow('Ear Detector', frame)\n",
    "    #cv2.imshow('Ear Detector', dst)\n",
    "    \n",
    "    #c = cv2.waitKey(1) \n",
    "    if cv2.waitKey(3000) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_map_images(img_dim,tar_dim,det_dim):\n",
    "    mul_factor = (det_dim[2]-det_dim[0])/tar_dim[1]\n",
    "    print(mul_factor)\n",
    "    new_tar_dim = tuple([int(mul_factor*x)for x in tar_dim])\n",
    "    print(new_tar_dim)\n",
    "    left_space = img_dim[1]-det_dim[3]\n",
    "    print(left_space)\n",
    "    if left_space>new_tar_dim[0]:\n",
    "        factor = mul_factor\n",
    "    else:\n",
    "        factor = left_space/tar_dim[0]\n",
    "    return factor   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27522935779816515\n",
      "(55, 30)\n",
      "109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27522935779816515"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = (95,66,125,116)\n",
    "im1 = tuple([2*x for x in im])\n",
    "im1\n",
    "factor = auto_map_images((225, 225),(201, 109),(95,66,125,116))\n",
    "factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('input.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for(x,y,w,h) infaces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for(ex,ey,ew,eh) in eyes\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "        cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#left_ear_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#left_ear_cascade = cv2.CascadeClassifier('haarcascade_upperbody.xml')\n",
    "left_ear_cascade = cv2.CascadeClassifier('haarcascade_mcs_upperbody.xml')\n",
    "\n",
    "if left_ear_cascade.empty():\n",
    "  raise IOError('Unable to load the left ear cascade classifier xml file')\n",
    "img = cv2.imread('image.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "left_ear = left_ear_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "print(len(left_ear))\n",
    "for (x,y,w,h) in left_ear:\n",
    "    cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 3)\n",
    "\n",
    "cv2.imshow('Ear Detector', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102  12  98 163]]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:245: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2befbf64272d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mroi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mroi_bg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask_inv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# roi_fg contains the orignal location of earring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:245: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n"
     ]
    }
   ],
   "source": [
    "from cv2 import cv2 \n",
    "import numpy as np \n",
    " \n",
    "left_ear_cascade = cv2.CascadeClassifier('haarcascade_mcs_leftear.xml') \n",
    "right_ear_cascade = cv2.CascadeClassifier('haarcascade_mcs_rightear.xml') \n",
    " \n",
    "if left_ear_cascade.empty(): \n",
    "  raise IOError('Unable to load the left ear cascade classifier xml file') \n",
    " \n",
    "if right_ear_cascade.empty(): \n",
    "  raise IOError('Unable to load the right ear cascade classifier xml file') \n",
    "scaling_factor = 0.5\n",
    "ear_img = cv2.imread('earring1.jpg', 1)\n",
    "ear_img = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "org_height, org_width, channel = ear_img.shape\n",
    "\n",
    "img2gray = cv2.cvtColor(ear_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# add a threshold\n",
    "ret, mask = cv2.threshold(img2gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "#cv2.imshow('Ear Detector', ear_img) \n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "#cv2.waitKey(10000) \n",
    "#cv2.imshow('Ear Detector', ear_img)  \n",
    "#cap = cv2.VideoCapture(0)\n",
    "#scaling_factor = 0.5\n",
    "while True:\n",
    "    #ret, frame = cap.read() \n",
    "    frame = cv2.imread('index1.jpg')\n",
    "    #frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  \n",
    "    left_ear = left_ear_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=3) \n",
    "    right_ear = right_ear_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=3) \n",
    "    print(left_ear)\n",
    "    for (x,y,w,h) in left_ear: \n",
    "        earring_height = h\n",
    "        earring_width = earring_height * org_width / org_height\n",
    "\n",
    "        x1 = int(x - (earring_width/4))\n",
    "        x2 = int(x + w + (earring_width/4))\n",
    "        y1 = int(y + h - (earring_height/2))\n",
    "        y2 = int(y + h + (earring_height/2))\n",
    "\n",
    "        earring_width = x2 - x1\n",
    "        earring_height = y2 - y1\n",
    "\n",
    "        earring = cv2.resize(ear_img, (earring_width,earring_height), interpolation = cv2.INTER_AREA)\n",
    "        mask = cv2.resize(mask, (earring_width,earring_height), interpolation = cv2.INTER_AREA)\n",
    "        mask_inv = cv2.resize(mask_inv, (earring_width,earring_height), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "        roi_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    " \n",
    "        # roi_fg contains the orignal location of earring\n",
    "        roi_fg = cv2.bitwise_and(earring,earring,mask = mask)\n",
    "     \n",
    "        # joining the roi_bg and roi_fg\n",
    "        dst = cv2.add(roi_bg,roi_fg)\n",
    " \n",
    "        # placing the joined image and saving to dst back over the original image\n",
    "        frame[y1:y2, x1:x2] = dst \n",
    "\n",
    "    for (x,y,w,h) in right_ear: \n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 3) \n",
    "\n",
    "    cv2.imshow('Ear Detector', frame) \n",
    "    #c = cv2.waitKey(1) \n",
    "    if cv2.waitKey(3000) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 275, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('index1.jpg')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8bca0561853f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimgshirt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'shirt.png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmusgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgshirt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#grayscale conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmusgray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0morig_mask_inv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "imgshirt = cv2.imread('shirt.png',1)\n",
    "musgray = cv2.cvtColor(imgshirt,cv2.COLOR_BGR2GRAY) #grayscale conversion\n",
    "ret, orig_mask = cv2.threshold(musgray,150 , 255, cv2.THRESH_BINARY)\n",
    "orig_mask_inv = cv2.bitwise_not(orig_mask)\n",
    "origshirtHeight, origshirtWidth = imgshirt.shape[:2]\n",
    "face_cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cap=cv2.VideoCapture(0)\n",
    "ret,img=cap.read()\n",
    "img_h, img_w = img.shape[:2]\n",
    "while True:\n",
    "    ret,img=cap.read()\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade.detectMultiScale(gray,1.3,5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "        face_w = w\n",
    "        face_h = h\n",
    "        face_x1 = x\n",
    "        face_x2 = face_x1 + face_h\n",
    "        face_y1 = y\n",
    "        face_y2 = face_y1 + face_h\n",
    "\n",
    "        # set the shirt size in relation to tracked face\n",
    "        shirtWidth = 3 * face_w\n",
    "        shirtHeight = int(shirtWidth * origshirtHeight / origshirtWidth)\n",
    "\n",
    "\n",
    "        shirt_x1 = face_x2 - int(face_w/2) - int(shirtWidth/2) #setting shirt centered wrt recognized face\n",
    "        shirt_x2 = shirt_x1 + shirtWidth\n",
    "        shirt_y1 = face_y2 + 5 # some padding between face and upper shirt. Depends on the shirt img\n",
    "        shirt_y2 = shirt_y1 + shirtHeight\n",
    "\n",
    "        # Check for clipping\n",
    "        if shirt_x1 < 0:\n",
    "            shirt_x1 = 0\n",
    "        if shirt_y1 < 0:\n",
    "            shirt_y1 = 0\n",
    "        if shirt_x2 > img_w:\n",
    "            shirt_x2 = img_w\n",
    "        if shirt_y2 > img_h:\n",
    "            shirt_y2 = img_h\n",
    "\n",
    "        shirtWidth = shirt_x2 - shirt_x1\n",
    "        shirtHeight = shirt_y2 - shirt_y1\n",
    "        if shirtWidth < 0 or shirtHeight < 0:\n",
    "            continue\n",
    "\n",
    "        # Re-size the original image and the masks to the shirt sizes\n",
    "        shirt = cv2.resize(imgshirt, (shirtWidth,shirtHeight), interpolation = cv2.INTER_AREA) #resize all,the masks you made,the originla image,everything\n",
    "        mask = cv2.resize(orig_mask, (shirtWidth,shirtHeight), interpolation = cv2.INTER_AREA)\n",
    "        mask_inv = cv2.resize(orig_mask_inv, (shirtWidth,shirtHeight), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        # take ROI for shirt from background equal to size of shirt image\n",
    "        roi = img[shirt_y1:shirt_y2, shirt_x1:shirt_x2]\n",
    "\n",
    "\n",
    "        # roi_bg contains the original image only where the shirt is not\n",
    "        # in the region that is the size of the shirt.\n",
    "        roi_bg = cv2.bitwise_and(roi,roi,mask = mask)\n",
    "        roi_fg = cv2.bitwise_and(shirt,shirt,mask = mask_inv)\n",
    "        dst = cv2.add(roi_bg,roi_fg)\n",
    "        img[shirt_y1:shirt_y2, shirt_x1:shirt_x2] = dst\n",
    "\n",
    "\n",
    "        break\n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break;\n",
    "cap.release() # Destroys the cap object\n",
    "cv2.destroyAllWindows() # Destroys all the windows created by imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 216 255 ...  15 255 217]\n",
      "[255 216 255 ...   0 255 217]\n",
      "[255 216 255 ...   7 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ...  25 255 217]\n",
      "[255 216 255 ...   0 255 217]\n",
      "[255 216 255 ...   0 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ...   1 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ...   1 255 217]\n",
      "[255 216 255 ...   3 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ...  15 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ...  15 255 217]\n",
      "[255 216 255 ...  71 255 217]\n",
      "[255 216 255 ... 128 255 217]\n",
      "[255 216 255 ... 159 255 217]\n",
      "[255 216 255 ...   0 255 217]\n",
      "[255 216 255 ...  15 255 217]\n",
      "[255 216 255 ...   3 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ...  31 255 217]\n",
      "[255 216 255 ...   1 255 217]\n",
      "[255 216 255 ...  31 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ...   7 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ...  31 255 217]\n",
      "[255 216 255 ...  31 255 217]\n",
      "[255 216 255 ... 129 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ...   7 255 217]\n",
      "[255 216 255 ...   7 255 217]\n",
      "[255 216 255 ... 185 255 217]\n",
      "[255 216 255 ... 163 255 217]\n",
      "[255 216 255 ... 103 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ... 231 255 217]\n",
      "[255 216 255 ...  15 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ...   7 255 217]\n",
      "[255 216 255 ... 129 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ...   7 255 217]\n",
      "[255 216 255 ... 207 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ...   0 255 217]\n",
      "[255 216 255 ...   1 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ...  12 255 217]\n",
      "[255 216 255 ...  31 255 217]\n",
      "[255 216 255 ... 129 255 217]\n",
      "[255 216 255 ...  15 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ...   3 255 217]\n",
      "[255 216 255 ... 103 255 217]\n",
      "[255 216 255 ...   3 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ...  31 255 217]\n",
      "[255 216 255 ... 143 255 217]\n",
      "[255 216 255 ...   7 255 217]\n",
      "[255 216 255 ...   7 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ...   7 255 217]\n",
      "[255 216 255 ...  31 255 217]\n",
      "[255 216 255 ...  15 255 217]\n",
      "[255 216 255 ...   3 255 217]\n",
      "[255 216 255 ...   1 255 217]\n",
      "[255 216 255 ...  15 255 217]\n",
      "[255 216 255 ...   1 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ...  25 255 217]\n",
      "[255 216 255 ...  15 255 217]\n",
      "[255 216 255 ...  35 255 217]\n",
      "[255 216 255 ...   0 255 217]\n",
      "[255 216 255 ...  15 255 217]\n",
      "[255 216 255 ...   1 255 217]\n",
      "[255 216 255 ...  31 255 217]\n",
      "[255 216 255 ...  31 255 217]\n",
      "[255 216 255 ...  15 255 217]\n",
      "[255 216 255 ...  31 255 217]\n",
      "[255 216 255 ...  31 255 217]\n",
      "[255 216 255 ...   1 255 217]\n",
      "[255 216 255 ...   3 255 217]\n",
      "[255 216 255 ...  63 255 217]\n",
      "[255 216 255 ...   1 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ...  31 255 217]\n",
      "[255 216 255 ...   1 255 217]\n",
      "[255 216 255 ...   0 255 217]\n",
      "[255 216 255 ...  31 255 217]\n",
      "[255 216 255 ...   0 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ...  31 255 217]\n",
      "[255 216 255 ...  15 255 217]\n",
      "[255 216 255 ... 159 255 217]\n",
      "[255 216 255 ...   3 255 217]\n",
      "[255 216 255 ...   0 255 217]\n",
      "[255 216 255 ...   0 255 217]\n",
      "[255 216 255 ... 127 255 217]\n",
      "[255 216 255 ...  31 255 217]\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "URL = \"http://192.168.0.107:8080/shot.jpg\"\n",
    "while True:    \n",
    "    img_arr = np.array(bytearray(urllib.request.urlopen(URL).read()),dtype=np.uint8)\n",
    "    print(img_arr)\n",
    "    img = cv2.imdecode(img_arr,-1)\n",
    "    cv2.imwrite('web1.jpg',img)\n",
    "    cv2.imshow('IPWebcam',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
